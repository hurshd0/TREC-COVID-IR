{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "# ----------------- Classics -------------------- #\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------- Pandas settings --------------- #\n",
    "# Removes rows and columns truncation of '...'\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# ------------------- Python libs ---------------- #\n",
    "import os, sys, re\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "from pathlib import Path\n",
    "ROOT_PATH = Path().resolve().parent\n",
    "sys.path.append(str(ROOT_PATH)) # Add folder root path\n",
    "\n",
    "import typing as t\n",
    "import timeit\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "# ------------------- NLP libs ---------------------- #\n",
    "from utils.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>title+abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ug7v899j</td>\n",
       "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
       "      <td>OBJECTIVE: This retrospective chart review des...</td>\n",
       "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02tnwd4m</td>\n",
       "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
       "      <td>Inflammatory diseases of the respiratory tract...</td>\n",
       "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ejv2xln0</td>\n",
       "      <td>Surfactant protein-D and pulmonary host defense</td>\n",
       "      <td>Surfactant protein-D (SP-D) participates in th...</td>\n",
       "      <td>Surfactant protein-D and pulmonary host defens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2b73a28n</td>\n",
       "      <td>Role of endothelin-1 in lung disease</td>\n",
       "      <td>Endothelin-1 (ET-1) is a 21 amino acid peptide...</td>\n",
       "      <td>Role of endothelin-1 in lung disease Endotheli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9785vg6d</td>\n",
       "      <td>Gene expression in epithelial cells in respons...</td>\n",
       "      <td>Respiratory syncytial virus (RSV) and pneumoni...</td>\n",
       "      <td>Gene expression in epithelial cells in respons...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid                                              title  \\\n",
       "0  ug7v899j  Clinical features of culture-proven Mycoplasma...   \n",
       "1  02tnwd4m  Nitric oxide: a pro-inflammatory mediator in l...   \n",
       "2  ejv2xln0    Surfactant protein-D and pulmonary host defense   \n",
       "3  2b73a28n               Role of endothelin-1 in lung disease   \n",
       "4  9785vg6d  Gene expression in epithelial cells in respons...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  OBJECTIVE: This retrospective chart review des...   \n",
       "1  Inflammatory diseases of the respiratory tract...   \n",
       "2  Surfactant protein-D (SP-D) participates in th...   \n",
       "3  Endothelin-1 (ET-1) is a 21 amino acid peptide...   \n",
       "4  Respiratory syncytial virus (RSV) and pneumoni...   \n",
       "\n",
       "                                      title+abstract  \n",
       "0  Clinical features of culture-proven Mycoplasma...  \n",
       "1  Nitric oxide: a pro-inflammatory mediator in l...  \n",
       "2  Surfactant protein-D and pulmonary host defens...  \n",
       "3  Role of endothelin-1 in lung disease Endotheli...  \n",
       "4  Gene expression in epithelial cells in respons...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORD19_PATH = Path('../data/input/trec_cord19_v0.csv')\n",
    "\n",
    "cord19 = pd.read_csv(CORD19_PATH)\n",
    "cord19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127617 entries, 0 to 127616\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   cord_uid        127617 non-null  object\n",
      " 1   title           127612 non-null  object\n",
      " 2   abstract        101395 non-null  object\n",
      " 3   title+abstract  127617 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "cord19.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cord_uid              0\n",
       "title                 5\n",
       "abstract          26222\n",
       "title+abstract        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cord19.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Separate title, abstract, and title+abstract data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((127612, 2), (101395, 2), (127617, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_only = cord19[['cord_uid', 'title']]\n",
    "abstract_only = cord19[['cord_uid', 'abstract']]\n",
    "title_abstract = cord19[['cord_uid', 'title+abstract']]\n",
    "\n",
    "# Drop empty rows\n",
    "title_only.dropna(inplace=True) \n",
    "abstract_only.dropna(inplace=True)\n",
    "title_abstract.dropna(inplace=True)\n",
    "title_only.shape, abstract_only.shape, title_abstract.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load queries (round 3 topics)\n",
    "\n",
    "Filename: `topics-rnd3.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries(input_fpath: Path, dtype: str = 'csv') -> pd.DataFrame:\n",
    "    \"\"\"Loads queries file and returns it as pandas data frame\n",
    "    \"\"\"\n",
    "    if dtype == 'csv':\n",
    "        df = pd.read_csv(input_fpath, quotechar='\"')\n",
    "        # for each column\n",
    "        for col in df.columns:\n",
    "            # check if the columns contains string data\n",
    "            if pd.api.types.is_string_dtype(df[col]):\n",
    "                df[col] = df[col].str.strip() # removes front and end white spaces\n",
    "                df[col] = df[col].str.replace('\\s{2,}', ' ') # remove double or more white spaces\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic-id</th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "      <th>narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>what is the origin of COVID-19</td>\n",
       "      <td>seeking range of information about the SARS-Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>coronavirus response to weather changes</td>\n",
       "      <td>how does the coronavirus respond to changes in...</td>\n",
       "      <td>seeking range of information about the SARS-Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>coronavirus immunity</td>\n",
       "      <td>will SARS-CoV2 infected people develop immunit...</td>\n",
       "      <td>seeking studies of immunity developed due to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>how do people die from the coronavirus</td>\n",
       "      <td>what causes death from Covid-19?</td>\n",
       "      <td>Studies looking at mechanisms of death from Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>animal models of COVID-19</td>\n",
       "      <td>what drugs have been active against SARS-CoV o...</td>\n",
       "      <td>Papers that describe the results of testing dr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic-id                                    query  \\\n",
       "0         1                       coronavirus origin   \n",
       "1         2  coronavirus response to weather changes   \n",
       "2         3                     coronavirus immunity   \n",
       "3         4   how do people die from the coronavirus   \n",
       "4         5                animal models of COVID-19   \n",
       "\n",
       "                                            question  \\\n",
       "0                     what is the origin of COVID-19   \n",
       "1  how does the coronavirus respond to changes in...   \n",
       "2  will SARS-CoV2 infected people develop immunit...   \n",
       "3                   what causes death from Covid-19?   \n",
       "4  what drugs have been active against SARS-CoV o...   \n",
       "\n",
       "                                           narrative  \n",
       "0  seeking range of information about the SARS-Co...  \n",
       "1  seeking range of information about the SARS-Co...  \n",
       "2  seeking studies of immunity developed due to i...  \n",
       "3  Studies looking at mechanisms of death from Co...  \n",
       "4  Papers that describe the results of testing dr...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY_FPATH = Path('../data/CORD-19/CORD-19/topics-rnd3.csv')\n",
    "query_df = load_queries(QUERY_FPATH)\n",
    "query_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. TF-IDF\n",
    "\n",
    "We will perform following steps to build document term matrix, run topic queries and evalute results using TREC-EVAL tool.\n",
    "\n",
    "Parameters to set:\n",
    "\n",
    "Tokenzier -> case-folding, NLTK stopwords removal, NLTK Wordnet Lemmatizing\n",
    "\n",
    "Step 1. Build TF-IDF matrix     \n",
    "Step 2. Query the topics   \n",
    "Step 3. Save the resulting result as TREC EVAL format\n",
    "\n",
    "For more info on how ot use TREC EVAL Tool visit my colab -> [tutorial](https://colab.research.google.com/drive/1_HuIn_Yd6y--wR4X0a9z2XdxEWgVkz9_?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tfidf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tfidf.py\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def create_tfidf_features(df, txt_col, tokenizer=None, max_features=None, min_df=2, max_df=0.9, ngram_range=(1,1)):\n",
    "    \"\"\"\n",
    "    Converts documents to document-term matrix using Scikit-learns TF-IDF Vectorizer\n",
    "    \"\"\"\n",
    "    if tokenizer is not None:\n",
    "        tokenizer = tokenizer.tokenize\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        decode_error='replace', \n",
    "        strip_accents='unicode', \n",
    "        tokenizer=tokenizer,\n",
    "        ngram_range=ngram_range, \n",
    "        max_features=max_features,\n",
    "        norm='l2',\n",
    "        use_idf=True,\n",
    "        smooth_idf=True,\n",
    "        sublinear_tf=True,\n",
    "        max_df=max_df,\n",
    "        min_df=min_df\n",
    "    )\n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(df[txt_col])\n",
    "    return X_tfidf, tfidf_vectorizer\n",
    "\n",
    "def calculate_similarity(X_tfidf, tfidf_vectorizer, query, top_k=5):\n",
    "    \"\"\" Vectorizes the `query` via `tfidf_vectorizer` and calculates the cosine similarity of\n",
    "    the `query` and `X_tfidf` (all the documents) and returns the `top_k` similar documents.\"\"\"\n",
    "    # Vectorize the query to the same length as documents\n",
    "    if not isinstance(query, list):\n",
    "        query = [query]\n",
    "    query_vec = tfidf_vectorizer.transform(query)\n",
    "    # Compute the cosine similarity between query_vec and all the documents\n",
    "    scores = cosine_similarity(X_tfidf,query_vec).flatten()\n",
    "    indices = np.argsort(scores)[-top_k:][::-1]\n",
    "    scores = scores[indices]\n",
    "    return list(zip(indices, scores))\n",
    "\n",
    "def get_ranked_lists(query, qid, run_name, corpus_df, X_tfidf, tfidf_vectorizer, top_k):\n",
    "    template = \"{} Q0 {} {} {:.6f} tfidf_baseline_{}\\n\"\n",
    "    similar_docs = calculate_similarity(X_tfidf, tfidf_vectorizer, query, top_k)\n",
    "    return [template.format(qid, corpus_df.iloc[idx]['cord_uid'], rank+1, score, run_name) for rank, (idx, score) in enumerate(similar_docs)]\n",
    "\n",
    "def write_results(out_fpath, corpus_df, query_df, query_id_col, query_txt_col, X_tfidf, tfidf_vectorizer, run_name, top_k=1000):\n",
    "    with open(out_fpath, 'w', encoding='utf-8') as writer:\n",
    "        for idx, topic in query_df.iterrows():\n",
    "            qid = topic[query_id_col]\n",
    "            query = topic[query_txt_col]\n",
    "            ranked_lists = get_ranked_lists(query, qid, run_name, corpus_df, X_tfidf, tfidf_vectorizer, top_k=top_k)\n",
    "            writer.writelines(ranked_lists)\n",
    "    print(f\"Wrote file @ {out_fpath}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from tfidf import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer('l-s-lm')\n",
    "X_tfidf, tfidf_vectorizer = create_tfidf_features(title_only, txt_col='title', tokenizer=tk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default TF-IDF settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Settings\n",
      "{   'analyzer': 'word',\n",
      "    'binary': False,\n",
      "    'decode_error': 'replace',\n",
      "    'dtype': <class 'numpy.float64'>,\n",
      "    'encoding': 'utf-8',\n",
      "    'input': 'content',\n",
      "    'lowercase': True,\n",
      "    'max_df': 0.9,\n",
      "    'max_features': None,\n",
      "    'min_df': 2,\n",
      "    'ngram_range': (1, 1),\n",
      "    'norm': 'l2',\n",
      "    'preprocessor': None,\n",
      "    'smooth_idf': True,\n",
      "    'stop_words': None,\n",
      "    'strip_accents': 'unicode',\n",
      "    'sublinear_tf': True,\n",
      "    'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "    'tokenizer': <bound method Tokenizer.tokenize of Tokenizer(config_codes=\"l-s-lm\")>,\n",
      "    'use_idf': True,\n",
      "    'vocabulary': None}\n",
      "\n",
      "Vocab.Size\n",
      "31540\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF Settings\")\n",
    "pp.pprint(tfidf_vectorizer.get_params())\n",
    "print(\"\\nVocab.Size\")\n",
    "print(len(tfidf_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Topic id: 1\n",
      "    Query: coronavirus origin\n",
      "    Question: what is the origin of COVID-19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic = query_df.loc[0]\n",
    "query = \"\"\"\n",
    "    Topic id: {}\n",
    "    Query: {}\n",
    "    Question: {}\n",
    "\"\"\".format(topic['topic-id'], topic.query, topic.question)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cord_uid: 4q24vxq3, title: Origins, score: 0.9030\n",
      "cord_uid: h8ahn8fw, title: Origin and evolution of the 2019 novel coronavirus, score: 0.6548\n",
      "cord_uid: gy8d8285, title: The Origin and Evolution of Viruses, score: 0.6443\n",
      "cord_uid: fk60pph3, title: The Origin and Prevention of Pandemics, score: 0.6438\n",
      "cord_uid: djpq7sgf, title: The origin of acute respiratory epidemics, score: 0.6328\n"
     ]
    }
   ],
   "source": [
    "results = calculate_similarity(X_tfidf, tfidf_vectorizer, topic.query, top_k=5)\n",
    "for idx, score in results:\n",
    "    print(\"cord_uid: {}, title: {}, score: {:.4f}\".format(title_only.iloc[idx]['cord_uid'], title_only.iloc[idx]['title'], score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While some of the documents match the query and results we are looking for, it's still not perfect so combining `title` and `abstract` should give better results.\n",
    "\n",
    "Now let's test out the results in TREC-COVID `qrel` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 Q0 4q24vxq3 1 0.903044 tfidf_baseline_title_only\\n',\n",
       " '1 Q0 h8ahn8fw 2 0.654781 tfidf_baseline_title_only\\n',\n",
       " '1 Q0 gy8d8285 3 0.644261 tfidf_baseline_title_only\\n',\n",
       " '1 Q0 fk60pph3 4 0.643778 tfidf_baseline_title_only\\n',\n",
       " '1 Q0 djpq7sgf 5 0.632806 tfidf_baseline_title_only\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ranked_lists(query_df.iloc[0]['query'], query_df.iloc[0]['topic-id'], 'title_only', title_only, X_tfidf, tfidf_vectorizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run it against all the topics and see what evaluation results we get against relevance judgement files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file @ ../data/output/tfidf_baseline_title_only.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_df = title_only\n",
    "run_name = 'title_only'\n",
    "query_txt_col = 'query'\n",
    "query_id_col = 'topic-id'\n",
    "out_fpath = Path('../data/output') / f'tfidf_baseline_{run_name}.txt'\n",
    "write_results(out_fpath, corpus_df, query_df, query_id_col, query_txt_col, X_tfidf, tfidf_vectorizer, run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `title` only + `query` only TREC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\ttfidf_baseline_title_only\n",
      "num_q                 \tall\t40\n",
      "num_ret               \tall\t40000\n",
      "num_rel               \tall\t10001\n",
      "num_rel_ret           \tall\t2265\n",
      "map                   \tall\t0.0720\n",
      "gm_map                \tall\t0.0217\n",
      "Rprec                 \tall\t0.1453\n",
      "bpref                 \tall\t0.2095\n",
      "recip_rank            \tall\t0.4983\n",
      "iprec_at_recall_0.00  \tall\t0.5594\n",
      "iprec_at_recall_0.10  \tall\t0.2493\n",
      "iprec_at_recall_0.20  \tall\t0.1513\n",
      "iprec_at_recall_0.30  \tall\t0.0893\n",
      "iprec_at_recall_0.40  \tall\t0.0335\n",
      "iprec_at_recall_0.50  \tall\t0.0162\n",
      "iprec_at_recall_0.60  \tall\t0.0000\n",
      "iprec_at_recall_0.70  \tall\t0.0000\n",
      "iprec_at_recall_0.80  \tall\t0.0000\n",
      "iprec_at_recall_0.90  \tall\t0.0000\n",
      "iprec_at_recall_1.00  \tall\t0.0000\n",
      "P_5                   \tall\t0.3350\n",
      "P_10                  \tall\t0.3100\n",
      "P_15                  \tall\t0.3000\n",
      "P_20                  \tall\t0.2950\n",
      "P_30                  \tall\t0.2817\n",
      "P_100                 \tall\t0.2188\n",
      "P_200                 \tall\t0.1636\n",
      "P_500                 \tall\t0.0921\n",
      "P_1000                \tall\t0.0566\n",
      "recall_5              \tall\t0.0083\n",
      "recall_10             \tall\t0.0154\n",
      "recall_15             \tall\t0.0213\n",
      "recall_20             \tall\t0.0277\n",
      "recall_30             \tall\t0.0388\n",
      "recall_100            \tall\t0.0966\n",
      "recall_200            \tall\t0.1395\n",
      "recall_500            \tall\t0.1909\n",
      "recall_1000           \tall\t0.2295\n",
      "infAP                 \tall\t0.0720\n",
      "gm_bpref              \tall\t0.1118\n",
      "Rprec_mult_0.20       \tall\t0.2557\n",
      "Rprec_mult_0.40       \tall\t0.2231\n",
      "Rprec_mult_0.60       \tall\t0.1915\n",
      "Rprec_mult_0.80       \tall\t0.1634\n",
      "Rprec_mult_1.00       \tall\t0.1453\n",
      "Rprec_mult_1.20       \tall\t0.1308\n",
      "Rprec_mult_1.40       \tall\t0.1197\n",
      "Rprec_mult_1.60       \tall\t0.1102\n",
      "Rprec_mult_1.80       \tall\t0.1020\n",
      "Rprec_mult_2.00       \tall\t0.0947\n",
      "utility               \tall\t-886.7500\n",
      "11pt_avg              \tall\t0.0999\n",
      "binG                  \tall\t0.0462\n",
      "G                     \tall\t0.0426\n",
      "ndcg                  \tall\t0.2295\n",
      "ndcg_rel              \tall\t0.2305\n",
      "Rndcg                 \tall\t0.1995\n",
      "ndcg_cut_5            \tall\t0.3000\n",
      "ndcg_cut_10           \tall\t0.2816\n",
      "ndcg_cut_15           \tall\t0.2735\n",
      "ndcg_cut_20           \tall\t0.2663\n",
      "ndcg_cut_30           \tall\t0.2548\n",
      "ndcg_cut_100          \tall\t0.2107\n",
      "ndcg_cut_200          \tall\t0.1943\n",
      "ndcg_cut_500          \tall\t0.2070\n",
      "ndcg_cut_1000         \tall\t0.2295\n",
      "map_cut_5             \tall\t0.0070\n",
      "map_cut_10            \tall\t0.0106\n",
      "map_cut_15            \tall\t0.0137\n",
      "map_cut_20            \tall\t0.0171\n",
      "map_cut_30            \tall\t0.0222\n",
      "map_cut_100           \tall\t0.0453\n",
      "map_cut_200           \tall\t0.0582\n",
      "map_cut_500           \tall\t0.0684\n",
      "map_cut_1000          \tall\t0.0720\n",
      "relative_P_5          \tall\t0.3350\n",
      "relative_P_10         \tall\t0.3100\n",
      "relative_P_15         \tall\t0.3000\n",
      "relative_P_20         \tall\t0.2950\n",
      "relative_P_30         \tall\t0.2817\n",
      "relative_P_100        \tall\t0.2194\n",
      "relative_P_200        \tall\t0.1852\n",
      "relative_P_500        \tall\t0.1917\n",
      "relative_P_1000       \tall\t0.2295\n",
      "success_1             \tall\t0.3750\n",
      "success_5             \tall\t0.6500\n",
      "success_10            \tall\t0.8250\n",
      "set_P                 \tall\t0.0566\n",
      "set_relative_P        \tall\t0.2295\n",
      "set_recall            \tall\t0.2295\n",
      "set_map               \tall\t0.0178\n",
      "set_F                 \tall\t0.0871\n",
      "num_nonrel_judged_ret \tall\t1827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_name = \"title_only\"\n",
    "path_to_qrel_file = \"../data/qrels/qrels-covid_d3_j0.5-3.txt\"\n",
    "path_to_result_file = f\"../data/output/tfidf_baseline_{run_name}.txt\"\n",
    "output_result_path = f\"../data/results/tfidf_baseline_{run_name}_trec_eval.txt\"\n",
    "os.system(\"trec_eval -c -m all_trec {} {} > {}\".format(path_to_qrel_file, path_to_result_file, output_result_path))\n",
    "with open(output_result_path, encoding='utf-8') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Metrics to look at:\n",
    "\n",
    "- `MAP` - 0.0720\n",
    "- `NDCG@10` - 0.2816\n",
    "- `P@5` - 0.3350\n",
    "- `R@1000` - 0.2295\n",
    "\n",
    "As expected `title` has poor results, now let's compare `abstract` and `title+abstract` to see if performance improves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) `abstract` only + `query` only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file @ ../data/output/tfidf_baseline_abstract_only.txt\n",
      "\n",
      "CPU times: user 24min 25s, sys: 3.47 s, total: 24min 28s\n",
      "Wall time: 24min 29s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# corpus_df = abstract_only\n",
    "# run_name = 'abstract_only'\n",
    "# tk = Tokenizer('l-s-lm')\n",
    "# query_txt_col = 'query'\n",
    "# query_id_col = 'topic-id'\n",
    "# X_tfidf, tfidf_vectorizer = create_tfidf_features(corpus_df, txt_col='abstract', tokenizer=tk)\n",
    "# out_fpath = Path('../data/output') / f'tfidf_baseline_{run_name}.txt'\n",
    "# write_results(out_fpath, corpus_df, query_df, X_tfidf, tfidf_vectorizer, run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell Output**\n",
    "\n",
    "```\n",
    "Wrote file @ ../data/output/tfidf_baseline_abstract_only.txt\n",
    "\n",
    "CPU times: user 23min 57s, sys: 2.45 s, total: 23min 59s\n",
    "Wall time: 23min 59s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Settings\n",
      "{   'analyzer': 'word',\n",
      "    'binary': False,\n",
      "    'decode_error': 'replace',\n",
      "    'dtype': <class 'numpy.float64'>,\n",
      "    'encoding': 'utf-8',\n",
      "    'input': 'content',\n",
      "    'lowercase': True,\n",
      "    'max_df': 0.9,\n",
      "    'max_features': None,\n",
      "    'min_df': 2,\n",
      "    'ngram_range': (1, 1),\n",
      "    'norm': 'l2',\n",
      "    'preprocessor': None,\n",
      "    'smooth_idf': True,\n",
      "    'stop_words': None,\n",
      "    'strip_accents': 'unicode',\n",
      "    'sublinear_tf': True,\n",
      "    'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "    'tokenizer': <bound method Tokenizer.tokenize of Tokenizer(config_codes=\"l-s-lm\")>,\n",
      "    'use_idf': True,\n",
      "    'vocabulary': None}\n",
      "\n",
      "Vocab.Size\n",
      "125512\n"
     ]
    }
   ],
   "source": [
    "# print(\"TF-IDF Settings\")\n",
    "# pp.pprint(tfidf_vectorizer.get_params())\n",
    "# print(\"\\nVocab.Size\")\n",
    "# print(len(tfidf_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell Output**\n",
    "\n",
    "```\n",
    "TF-IDF Settings\n",
    "{   'analyzer': 'word',\n",
    "    'binary': False,\n",
    "    'decode_error': 'replace',\n",
    "    'dtype': <class 'numpy.float64'>,\n",
    "    'encoding': 'utf-8',\n",
    "    'input': 'content',\n",
    "    'lowercase': True,\n",
    "    'max_df': 0.9,\n",
    "    'max_features': None,\n",
    "    'min_df': 2,\n",
    "    'ngram_range': (1, 1),\n",
    "    'norm': 'l2',\n",
    "    'preprocessor': None,\n",
    "    'smooth_idf': True,\n",
    "    'stop_words': None,\n",
    "    'strip_accents': 'unicode',\n",
    "    'sublinear_tf': True,\n",
    "    'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "    'tokenizer': <bound method Tokenizer.tokenize of Tokenizer(config_codes=\"l-s-lm\")>,\n",
    "    'use_idf': True,\n",
    "    'vocabulary': None}\n",
    "\n",
    "Vocab.Size\n",
    "125512\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\ttfidf_baseline_abstract_only\n",
      "num_q                 \tall\t40\n",
      "num_ret               \tall\t40000\n",
      "num_rel               \tall\t10001\n",
      "num_rel_ret           \tall\t3314\n",
      "map                   \tall\t0.1069\n",
      "gm_map                \tall\t0.0514\n",
      "Rprec                 \tall\t0.1905\n",
      "bpref                 \tall\t0.2914\n",
      "recip_rank            \tall\t0.5229\n",
      "iprec_at_recall_0.00  \tall\t0.5997\n",
      "iprec_at_recall_0.10  \tall\t0.3161\n",
      "iprec_at_recall_0.20  \tall\t0.2263\n",
      "iprec_at_recall_0.30  \tall\t0.1602\n",
      "iprec_at_recall_0.40  \tall\t0.0971\n",
      "iprec_at_recall_0.50  \tall\t0.0553\n",
      "iprec_at_recall_0.60  \tall\t0.0263\n",
      "iprec_at_recall_0.70  \tall\t0.0029\n",
      "iprec_at_recall_0.80  \tall\t0.0000\n",
      "iprec_at_recall_0.90  \tall\t0.0000\n",
      "iprec_at_recall_1.00  \tall\t0.0000\n",
      "P_5                   \tall\t0.3800\n",
      "P_10                  \tall\t0.3500\n",
      "P_15                  \tall\t0.3617\n",
      "P_20                  \tall\t0.3500\n",
      "P_30                  \tall\t0.3225\n",
      "P_100                 \tall\t0.2567\n",
      "P_200                 \tall\t0.2047\n",
      "P_500                 \tall\t0.1284\n",
      "P_1000                \tall\t0.0829\n",
      "recall_5              \tall\t0.0102\n",
      "recall_10             \tall\t0.0175\n",
      "recall_15             \tall\t0.0274\n",
      "recall_20             \tall\t0.0351\n",
      "recall_30             \tall\t0.0478\n",
      "recall_100            \tall\t0.1192\n",
      "recall_200            \tall\t0.1812\n",
      "recall_500            \tall\t0.2774\n",
      "recall_1000           \tall\t0.3480\n",
      "infAP                 \tall\t0.1069\n",
      "gm_bpref              \tall\t0.2244\n",
      "Rprec_mult_0.20       \tall\t0.3136\n",
      "Rprec_mult_0.40       \tall\t0.2714\n",
      "Rprec_mult_0.60       \tall\t0.2377\n",
      "Rprec_mult_0.80       \tall\t0.2097\n",
      "Rprec_mult_1.00       \tall\t0.1905\n",
      "Rprec_mult_1.20       \tall\t0.1743\n",
      "Rprec_mult_1.40       \tall\t0.1613\n",
      "Rprec_mult_1.60       \tall\t0.1503\n",
      "Rprec_mult_1.80       \tall\t0.1404\n",
      "Rprec_mult_2.00       \tall\t0.1312\n",
      "utility               \tall\t-834.3000\n",
      "11pt_avg              \tall\t0.1349\n",
      "binG                  \tall\t0.0656\n",
      "G                     \tall\t0.0570\n",
      "ndcg                  \tall\t0.3140\n",
      "ndcg_rel              \tall\t0.2969\n",
      "Rndcg                 \tall\t0.2518\n",
      "ndcg_cut_5            \tall\t0.3029\n",
      "ndcg_cut_10           \tall\t0.2899\n",
      "ndcg_cut_15           \tall\t0.3000\n",
      "ndcg_cut_20           \tall\t0.2971\n",
      "ndcg_cut_30           \tall\t0.2806\n",
      "ndcg_cut_100          \tall\t0.2404\n",
      "ndcg_cut_200          \tall\t0.2353\n",
      "ndcg_cut_500          \tall\t0.2725\n",
      "ndcg_cut_1000         \tall\t0.3140\n",
      "map_cut_5             \tall\t0.0078\n",
      "map_cut_10            \tall\t0.0123\n",
      "map_cut_15            \tall\t0.0177\n",
      "map_cut_20            \tall\t0.0217\n",
      "map_cut_30            \tall\t0.0279\n",
      "map_cut_100           \tall\t0.0594\n",
      "map_cut_200           \tall\t0.0790\n",
      "map_cut_500           \tall\t0.0983\n",
      "map_cut_1000          \tall\t0.1069\n",
      "relative_P_5          \tall\t0.3800\n",
      "relative_P_10         \tall\t0.3500\n",
      "relative_P_15         \tall\t0.3617\n",
      "relative_P_20         \tall\t0.3500\n",
      "relative_P_30         \tall\t0.3225\n",
      "relative_P_100        \tall\t0.2584\n",
      "relative_P_200        \tall\t0.2356\n",
      "relative_P_500        \tall\t0.2786\n",
      "relative_P_1000       \tall\t0.3480\n",
      "success_1             \tall\t0.3750\n",
      "success_5             \tall\t0.7500\n",
      "success_10            \tall\t0.8750\n",
      "set_P                 \tall\t0.0829\n",
      "set_relative_P        \tall\t0.3480\n",
      "set_recall            \tall\t0.3480\n",
      "set_map               \tall\t0.0341\n",
      "set_F                 \tall\t0.1281\n",
      "num_nonrel_judged_ret \tall\t3085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_name = \"abstract_only\"\n",
    "path_to_qrel_file = \"../data/qrels/qrels-covid_d3_j0.5-3.txt\"\n",
    "path_to_result_file = f\"../data/output/tfidf_baseline_{run_name}.txt\"\n",
    "output_result_path = f\"../data/results/tfidf_baseline_{run_name}_trec_eval.txt\"\n",
    "os.system(\"trec_eval -c -m all_trec {} {} > {}\".format(path_to_qrel_file, path_to_result_file, output_result_path))\n",
    "with open(output_result_path, encoding='utf-8') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Metrics\n",
    "\n",
    "- `MAP` - 0.1069\n",
    "- `NDCG@10` - 0.2899\n",
    "- `P@5` - 0.38\n",
    "- `R@1000` - 0.3480\n",
    "\n",
    "There is slight improvement, using only abstract and query. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) `title+abstract` only  + `query` only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file @ ../data/output/tfidf_baseline_title_abstract.txt\n",
      "\n",
      "CPU times: user 26min 34s, sys: 3.8 s, total: 26min 38s\n",
      "Wall time: 26min 38s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# corpus_df = title_abstract\n",
    "# run_name = 'title_abstract'\n",
    "# tk = Tokenizer('l-s-lm')\n",
    "# query_txt_col = 'query'\n",
    "# query_id_col = 'topic-id'\n",
    "# X_tfidf, tfidf_vectorizer = create_tfidf_features(corpus_df, txt_col='title+abstract', tokenizer=tk)\n",
    "# out_fpath = Path('../data/output') / f'tfidf_baseline_{run_name}.txt'\n",
    "# write_results(out_fpath, corpus_df, query_df, query_id_col, query_txt_col, X_tfidf, tfidf_vectorizer, run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell Output**\n",
    "\n",
    "```\n",
    "Wrote file @ ../data/output/tfidf_baseline_title_abstract.txt\n",
    "\n",
    "CPU times: user 26min 11s, sys: 2.76 s, total: 26min 14s\n",
    "Wall time: 26min 14s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Settings\n",
      "{   'analyzer': 'word',\n",
      "    'binary': False,\n",
      "    'decode_error': 'replace',\n",
      "    'dtype': <class 'numpy.float64'>,\n",
      "    'encoding': 'utf-8',\n",
      "    'input': 'content',\n",
      "    'lowercase': True,\n",
      "    'max_df': 0.9,\n",
      "    'max_features': None,\n",
      "    'min_df': 2,\n",
      "    'ngram_range': (1, 1),\n",
      "    'norm': 'l2',\n",
      "    'preprocessor': None,\n",
      "    'smooth_idf': True,\n",
      "    'stop_words': None,\n",
      "    'strip_accents': 'unicode',\n",
      "    'sublinear_tf': True,\n",
      "    'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "    'tokenizer': <bound method Tokenizer.tokenize of Tokenizer(config_codes=\"l-s-lm\")>,\n",
      "    'use_idf': True,\n",
      "    'vocabulary': None}\n",
      "\n",
      "Vocab.Size\n",
      "130897\n"
     ]
    }
   ],
   "source": [
    "# print(\"TF-IDF Settings\")\n",
    "# pp.pprint(tfidf_vectorizer.get_params())\n",
    "# print(\"\\nVocab.Size\")\n",
    "# print(len(tfidf_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell Output**\n",
    "\n",
    "```\n",
    "TF-IDF Settings\n",
    "{   'analyzer': 'word',\n",
    "    'binary': False,\n",
    "    'decode_error': 'replace',\n",
    "    'dtype': <class 'numpy.float64'>,\n",
    "    'encoding': 'utf-8',\n",
    "    'input': 'content',\n",
    "    'lowercase': True,\n",
    "    'max_df': 0.9,\n",
    "    'max_features': None,\n",
    "    'min_df': 2,\n",
    "    'ngram_range': (1, 1),\n",
    "    'norm': 'l2',\n",
    "    'preprocessor': None,\n",
    "    'smooth_idf': True,\n",
    "    'stop_words': None,\n",
    "    'strip_accents': 'unicode',\n",
    "    'sublinear_tf': True,\n",
    "    'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "    'tokenizer': <bound method Tokenizer.tokenize of Tokenizer(config_codes=\"l-s-lm\")>,\n",
    "    'use_idf': True,\n",
    "    'vocabulary': None}\n",
    "\n",
    "Vocab.Size\n",
    "130897\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\ttfidf_baseline_title_abstract\n",
      "num_q                 \tall\t40\n",
      "num_ret               \tall\t40000\n",
      "num_rel               \tall\t10001\n",
      "num_rel_ret           \tall\t3084\n",
      "map                   \tall\t0.0807\n",
      "gm_map                \tall\t0.0287\n",
      "Rprec                 \tall\t0.1637\n",
      "bpref                 \tall\t0.2856\n",
      "recip_rank            \tall\t0.3841\n",
      "iprec_at_recall_0.00  \tall\t0.4523\n",
      "iprec_at_recall_0.10  \tall\t0.2132\n",
      "iprec_at_recall_0.20  \tall\t0.1635\n",
      "iprec_at_recall_0.30  \tall\t0.1185\n",
      "iprec_at_recall_0.40  \tall\t0.0912\n",
      "iprec_at_recall_0.50  \tall\t0.0547\n",
      "iprec_at_recall_0.60  \tall\t0.0234\n",
      "iprec_at_recall_0.70  \tall\t0.0133\n",
      "iprec_at_recall_0.80  \tall\t0.0000\n",
      "iprec_at_recall_0.90  \tall\t0.0000\n",
      "iprec_at_recall_1.00  \tall\t0.0000\n",
      "P_5                   \tall\t0.2300\n",
      "P_10                  \tall\t0.2450\n",
      "P_15                  \tall\t0.2350\n",
      "P_20                  \tall\t0.2237\n",
      "P_30                  \tall\t0.2100\n",
      "P_100                 \tall\t0.1857\n",
      "P_200                 \tall\t0.1697\n",
      "P_500                 \tall\t0.1178\n",
      "P_1000                \tall\t0.0771\n",
      "recall_5              \tall\t0.0053\n",
      "recall_10             \tall\t0.0118\n",
      "recall_15             \tall\t0.0170\n",
      "recall_20             \tall\t0.0212\n",
      "recall_30             \tall\t0.0298\n",
      "recall_100            \tall\t0.0854\n",
      "recall_200            \tall\t0.1520\n",
      "recall_500            \tall\t0.2530\n",
      "recall_1000           \tall\t0.3252\n",
      "infAP                 \tall\t0.0807\n",
      "gm_bpref              \tall\t0.2016\n",
      "Rprec_mult_0.20       \tall\t0.2073\n",
      "Rprec_mult_0.40       \tall\t0.1954\n",
      "Rprec_mult_0.60       \tall\t0.1817\n",
      "Rprec_mult_0.80       \tall\t0.1751\n",
      "Rprec_mult_1.00       \tall\t0.1637\n",
      "Rprec_mult_1.20       \tall\t0.1534\n",
      "Rprec_mult_1.40       \tall\t0.1413\n",
      "Rprec_mult_1.60       \tall\t0.1316\n",
      "Rprec_mult_1.80       \tall\t0.1235\n",
      "Rprec_mult_2.00       \tall\t0.1168\n",
      "utility               \tall\t-845.8000\n",
      "11pt_avg              \tall\t0.1027\n",
      "binG                  \tall\t0.0532\n",
      "G                     \tall\t0.0494\n",
      "ndcg                  \tall\t0.2772\n",
      "ndcg_rel              \tall\t0.2476\n",
      "Rndcg                 \tall\t0.2067\n",
      "ndcg_cut_5            \tall\t0.2002\n",
      "ndcg_cut_10           \tall\t0.2031\n",
      "ndcg_cut_15           \tall\t0.1983\n",
      "ndcg_cut_20           \tall\t0.1898\n",
      "ndcg_cut_30           \tall\t0.1816\n",
      "ndcg_cut_100          \tall\t0.1699\n",
      "ndcg_cut_200          \tall\t0.1853\n",
      "ndcg_cut_500          \tall\t0.2346\n",
      "ndcg_cut_1000         \tall\t0.2772\n",
      "map_cut_5             \tall\t0.0039\n",
      "map_cut_10            \tall\t0.0072\n",
      "map_cut_15            \tall\t0.0094\n",
      "map_cut_20            \tall\t0.0112\n",
      "map_cut_30            \tall\t0.0145\n",
      "map_cut_100           \tall\t0.0329\n",
      "map_cut_200           \tall\t0.0518\n",
      "map_cut_500           \tall\t0.0726\n",
      "map_cut_1000          \tall\t0.0807\n",
      "relative_P_5          \tall\t0.2300\n",
      "relative_P_10         \tall\t0.2450\n",
      "relative_P_15         \tall\t0.2350\n",
      "relative_P_20         \tall\t0.2237\n",
      "relative_P_30         \tall\t0.2100\n",
      "relative_P_100        \tall\t0.1867\n",
      "relative_P_200        \tall\t0.1939\n",
      "relative_P_500        \tall\t0.2540\n",
      "relative_P_1000       \tall\t0.3252\n",
      "success_1             \tall\t0.2500\n",
      "success_5             \tall\t0.5000\n",
      "success_10            \tall\t0.7000\n",
      "set_P                 \tall\t0.0771\n",
      "set_relative_P        \tall\t0.3252\n",
      "set_recall            \tall\t0.3252\n",
      "set_map               \tall\t0.0324\n",
      "set_F                 \tall\t0.1195\n",
      "num_nonrel_judged_ret \tall\t2405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_name = \"title_abstract\"\n",
    "path_to_qrel_file = \"../data/qrels/qrels-covid_d3_j0.5-3.txt\"\n",
    "path_to_result_file = f\"../data/output/tfidf_baseline_{run_name}.txt\"\n",
    "output_result_path = f\"../data/results/tfidf_baseline_{run_name}_trec_eval.txt\"\n",
    "os.system(\"trec_eval -c -m all_trec {} {} > {}\".format(path_to_qrel_file, path_to_result_file, output_result_path))\n",
    "with open(output_result_path, encoding='utf-8') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Metrics to look at,\n",
    "\n",
    "- `MAP` - 0.0807\n",
    "- `NDCG@10` - 0.2031\n",
    "- `P@5` - 0.2300\n",
    "- `R@1000` - 0.3252\n",
    "\n",
    "Performance got hurt most likely due to more non-relevant documents that didn't contain `Abstract` and only had `Title` and thus affected the retrieved results. \n",
    "\n",
    "Now let's see if performance can be improved if we can do proper \"Query Construction\" by combining `query` and `question` columns on `abstract` only dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) `abstract` + `query+question`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic-id</th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "      <th>narrative</th>\n",
       "      <th>query+question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>what is the origin of COVID-19</td>\n",
       "      <td>seeking range of information about the SARS-Co...</td>\n",
       "      <td>coronavirus origin what is the origin of COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>coronavirus response to weather changes</td>\n",
       "      <td>how does the coronavirus respond to changes in...</td>\n",
       "      <td>seeking range of information about the SARS-Co...</td>\n",
       "      <td>coronavirus response to weather changes how do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>coronavirus immunity</td>\n",
       "      <td>will SARS-CoV2 infected people develop immunit...</td>\n",
       "      <td>seeking studies of immunity developed due to i...</td>\n",
       "      <td>coronavirus immunity will SARS-CoV2 infected p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>how do people die from the coronavirus</td>\n",
       "      <td>what causes death from Covid-19?</td>\n",
       "      <td>Studies looking at mechanisms of death from Co...</td>\n",
       "      <td>how do people die from the coronavirus what ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>animal models of COVID-19</td>\n",
       "      <td>what drugs have been active against SARS-CoV o...</td>\n",
       "      <td>Papers that describe the results of testing dr...</td>\n",
       "      <td>animal models of COVID-19 what drugs have been...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic-id                                    query  \\\n",
       "0         1                       coronavirus origin   \n",
       "1         2  coronavirus response to weather changes   \n",
       "2         3                     coronavirus immunity   \n",
       "3         4   how do people die from the coronavirus   \n",
       "4         5                animal models of COVID-19   \n",
       "\n",
       "                                            question  \\\n",
       "0                     what is the origin of COVID-19   \n",
       "1  how does the coronavirus respond to changes in...   \n",
       "2  will SARS-CoV2 infected people develop immunit...   \n",
       "3                   what causes death from Covid-19?   \n",
       "4  what drugs have been active against SARS-CoV o...   \n",
       "\n",
       "                                           narrative  \\\n",
       "0  seeking range of information about the SARS-Co...   \n",
       "1  seeking range of information about the SARS-Co...   \n",
       "2  seeking studies of immunity developed due to i...   \n",
       "3  Studies looking at mechanisms of death from Co...   \n",
       "4  Papers that describe the results of testing dr...   \n",
       "\n",
       "                                      query+question  \n",
       "0  coronavirus origin what is the origin of COVID-19  \n",
       "1  coronavirus response to weather changes how do...  \n",
       "2  coronavirus immunity will SARS-CoV2 infected p...  \n",
       "3  how do people die from the coronavirus what ca...  \n",
       "4  animal models of COVID-19 what drugs have been...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df['query+question'] = query_df['query'] + ' ' + query_df['question']\n",
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file @ ../data/output/tfidf_baseline_abstract_query_question.txt\n",
      "\n",
      "CPU times: user 24min 11s, sys: 2.8 s, total: 24min 14s\n",
      "Wall time: 24min 14s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# corpus_df = abstract_only\n",
    "# run_name = 'abstract_query_question'\n",
    "# tk = Tokenizer('l-s-lm')\n",
    "# query_txt_col = 'query'\n",
    "# query_id_col = 'topic-id'\n",
    "# X_tfidf, tfidf_vectorizer = create_tfidf_features(corpus_df, txt_col='abstract', tokenizer=tk)\n",
    "# out_fpath = Path('../data/output') / f'tfidf_baseline_{run_name}.txt'\n",
    "# write_results(out_fpath, corpus_df, query_df, query_id_col, query_txt_col, X_tfidf, tfidf_vectorizer, run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell Output**\n",
    "\n",
    "```\n",
    "Wrote file @ ../data/output/tfidf_baseline_abstract_query_question.txt\n",
    "\n",
    "CPU times: user 24min 10s, sys: 2.7 s, total: 24min 12s\n",
    "Wall time: 24min 12s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Settings\n",
      "{   'analyzer': 'word',\n",
      "    'binary': False,\n",
      "    'decode_error': 'replace',\n",
      "    'dtype': <class 'numpy.float64'>,\n",
      "    'encoding': 'utf-8',\n",
      "    'input': 'content',\n",
      "    'lowercase': True,\n",
      "    'max_df': 0.9,\n",
      "    'max_features': None,\n",
      "    'min_df': 2,\n",
      "    'ngram_range': (1, 1),\n",
      "    'norm': 'l2',\n",
      "    'preprocessor': None,\n",
      "    'smooth_idf': True,\n",
      "    'stop_words': None,\n",
      "    'strip_accents': 'unicode',\n",
      "    'sublinear_tf': True,\n",
      "    'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "    'tokenizer': <bound method Tokenizer.tokenize of Tokenizer(config_codes=\"l-s-lm\")>,\n",
      "    'use_idf': True,\n",
      "    'vocabulary': None}\n",
      "\n",
      "Vocab.Size\n",
      "125512\n"
     ]
    }
   ],
   "source": [
    "# print(\"TF-IDF Settings\")\n",
    "# pp.pprint(tfidf_vectorizer.get_params())\n",
    "# print(\"\\nVocab.Size\")\n",
    "# print(len(tfidf_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell Output**\n",
    "\n",
    "```\n",
    "TF-IDF Settings\n",
    "{   'analyzer': 'word',\n",
    "    'binary': False,\n",
    "    'decode_error': 'replace',\n",
    "    'dtype': <class 'numpy.float64'>,\n",
    "    'encoding': 'utf-8',\n",
    "    'input': 'content',\n",
    "    'lowercase': True,\n",
    "    'max_df': 0.9,\n",
    "    'max_features': None,\n",
    "    'min_df': 2,\n",
    "    'ngram_range': (1, 1),\n",
    "    'norm': 'l2',\n",
    "    'preprocessor': None,\n",
    "    'smooth_idf': True,\n",
    "    'stop_words': None,\n",
    "    'strip_accents': 'unicode',\n",
    "    'sublinear_tf': True,\n",
    "    'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "    'tokenizer': <bound method Tokenizer.tokenize of Tokenizer(config_codes=\"l-s-lm\")>,\n",
    "    'use_idf': True,\n",
    "    'vocabulary': None}\n",
    "\n",
    "Vocab.Size\n",
    "125512\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\ttfidf_baseline_abstract_query_question\n",
      "num_q                 \tall\t40\n",
      "num_ret               \tall\t40000\n",
      "num_rel               \tall\t10001\n",
      "num_rel_ret           \tall\t3314\n",
      "map                   \tall\t0.1069\n",
      "gm_map                \tall\t0.0514\n",
      "Rprec                 \tall\t0.1905\n",
      "bpref                 \tall\t0.2914\n",
      "recip_rank            \tall\t0.5229\n",
      "iprec_at_recall_0.00  \tall\t0.5997\n",
      "iprec_at_recall_0.10  \tall\t0.3161\n",
      "iprec_at_recall_0.20  \tall\t0.2263\n",
      "iprec_at_recall_0.30  \tall\t0.1602\n",
      "iprec_at_recall_0.40  \tall\t0.0971\n",
      "iprec_at_recall_0.50  \tall\t0.0553\n",
      "iprec_at_recall_0.60  \tall\t0.0263\n",
      "iprec_at_recall_0.70  \tall\t0.0029\n",
      "iprec_at_recall_0.80  \tall\t0.0000\n",
      "iprec_at_recall_0.90  \tall\t0.0000\n",
      "iprec_at_recall_1.00  \tall\t0.0000\n",
      "P_5                   \tall\t0.3800\n",
      "P_10                  \tall\t0.3500\n",
      "P_15                  \tall\t0.3617\n",
      "P_20                  \tall\t0.3500\n",
      "P_30                  \tall\t0.3225\n",
      "P_100                 \tall\t0.2567\n",
      "P_200                 \tall\t0.2047\n",
      "P_500                 \tall\t0.1284\n",
      "P_1000                \tall\t0.0829\n",
      "recall_5              \tall\t0.0102\n",
      "recall_10             \tall\t0.0175\n",
      "recall_15             \tall\t0.0274\n",
      "recall_20             \tall\t0.0351\n",
      "recall_30             \tall\t0.0478\n",
      "recall_100            \tall\t0.1192\n",
      "recall_200            \tall\t0.1812\n",
      "recall_500            \tall\t0.2774\n",
      "recall_1000           \tall\t0.3480\n",
      "infAP                 \tall\t0.1069\n",
      "gm_bpref              \tall\t0.2244\n",
      "Rprec_mult_0.20       \tall\t0.3136\n",
      "Rprec_mult_0.40       \tall\t0.2714\n",
      "Rprec_mult_0.60       \tall\t0.2377\n",
      "Rprec_mult_0.80       \tall\t0.2097\n",
      "Rprec_mult_1.00       \tall\t0.1905\n",
      "Rprec_mult_1.20       \tall\t0.1743\n",
      "Rprec_mult_1.40       \tall\t0.1613\n",
      "Rprec_mult_1.60       \tall\t0.1503\n",
      "Rprec_mult_1.80       \tall\t0.1404\n",
      "Rprec_mult_2.00       \tall\t0.1312\n",
      "utility               \tall\t-834.3000\n",
      "11pt_avg              \tall\t0.1349\n",
      "binG                  \tall\t0.0656\n",
      "G                     \tall\t0.0570\n",
      "ndcg                  \tall\t0.3140\n",
      "ndcg_rel              \tall\t0.2969\n",
      "Rndcg                 \tall\t0.2518\n",
      "ndcg_cut_5            \tall\t0.3029\n",
      "ndcg_cut_10           \tall\t0.2899\n",
      "ndcg_cut_15           \tall\t0.3000\n",
      "ndcg_cut_20           \tall\t0.2971\n",
      "ndcg_cut_30           \tall\t0.2806\n",
      "ndcg_cut_100          \tall\t0.2404\n",
      "ndcg_cut_200          \tall\t0.2353\n",
      "ndcg_cut_500          \tall\t0.2725\n",
      "ndcg_cut_1000         \tall\t0.3140\n",
      "map_cut_5             \tall\t0.0078\n",
      "map_cut_10            \tall\t0.0123\n",
      "map_cut_15            \tall\t0.0177\n",
      "map_cut_20            \tall\t0.0217\n",
      "map_cut_30            \tall\t0.0279\n",
      "map_cut_100           \tall\t0.0594\n",
      "map_cut_200           \tall\t0.0790\n",
      "map_cut_500           \tall\t0.0983\n",
      "map_cut_1000          \tall\t0.1069\n",
      "relative_P_5          \tall\t0.3800\n",
      "relative_P_10         \tall\t0.3500\n",
      "relative_P_15         \tall\t0.3617\n",
      "relative_P_20         \tall\t0.3500\n",
      "relative_P_30         \tall\t0.3225\n",
      "relative_P_100        \tall\t0.2584\n",
      "relative_P_200        \tall\t0.2356\n",
      "relative_P_500        \tall\t0.2786\n",
      "relative_P_1000       \tall\t0.3480\n",
      "success_1             \tall\t0.3750\n",
      "success_5             \tall\t0.7500\n",
      "success_10            \tall\t0.8750\n",
      "set_P                 \tall\t0.0829\n",
      "set_relative_P        \tall\t0.3480\n",
      "set_recall            \tall\t0.3480\n",
      "set_map               \tall\t0.0341\n",
      "set_F                 \tall\t0.1281\n",
      "num_nonrel_judged_ret \tall\t3085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_name = \"abstract_query_question\"\n",
    "path_to_qrel_file = \"../data/qrels/qrels-covid_d3_j0.5-3.txt\"\n",
    "path_to_result_file = f\"../data/output/tfidf_baseline_{run_name}.txt\"\n",
    "output_result_path = f\"../data/results/tfidf_baseline_{run_name}_trec_eval.txt\"\n",
    "os.system(\"trec_eval -c -m all_trec {} {} > {}\".format(path_to_qrel_file, path_to_result_file, output_result_path))\n",
    "with open(output_result_path, encoding='utf-8') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Metrics,\n",
    "\n",
    "- `MAP` - 0.1215\n",
    "- `NDCG@10` - 0.2937\n",
    "- `P@5` - 0.3150\n",
    "- `R@1000` - 0.4007\n",
    "\n",
    "`NDCG@10` and `Recall@1000` so adding `question` to the `query` provides more context to the \"information need\" and as such we see better Recall, MAP, and NDCG. \n",
    "\n",
    "Now let's keep the documents that have abstract but add `title` to see if performance improves.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) `abstract` + enhance with `title` + (`query` + `question`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>title+abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ug7v899j</td>\n",
       "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02tnwd4m</td>\n",
       "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ejv2xln0</td>\n",
       "      <td>Surfactant protein-D and pulmonary host defens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2b73a28n</td>\n",
       "      <td>Role of endothelin-1 in lung disease Endotheli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9785vg6d</td>\n",
       "      <td>Gene expression in epithelial cells in respons...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid                                     title+abstract\n",
       "0  ug7v899j  Clinical features of culture-proven Mycoplasma...\n",
       "1  02tnwd4m  Nitric oxide: a pro-inflammatory mediator in l...\n",
       "2  ejv2xln0  Surfactant protein-D and pulmonary host defens...\n",
       "3  2b73a28n  Role of endothelin-1 in lung disease Endotheli...\n",
       "4  9785vg6d  Gene expression in epithelial cells in respons..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop documents that don't have abstract\n",
    "enhanced_abstract = cord19.dropna(subset=['abstract'])\n",
    "\n",
    "# Verify the shape matches with the abstract only data frame\n",
    "assert enhanced_abstract.shape[0] == abstract_only.shape[0]\n",
    "\n",
    "# Drop title and abstract columns\n",
    "enhanced_abstract = enhanced_abstract.drop(['title', 'abstract'], axis=1)\n",
    "enhanced_abstract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify there is no missing values again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 101395 entries, 0 to 127616\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   cord_uid        101395 non-null  object\n",
      " 1   title+abstract  101395 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "enhanced_abstract.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corpus_df = enhanced_abstract\n",
    "run_name = 'enhanced_abstract_query_question'\n",
    "tk = Tokenizer('l-s-lm')\n",
    "query_txt_col = 'query+question'\n",
    "query_id_col = 'topic-id'\n",
    "X_tfidf, tfidf_vectorizer = create_tfidf_features(corpus_df, txt_col='title+abstract', tokenizer=tk)\n",
    "out_fpath = Path('../data/output') / f'tfidf_baseline_{run_name}.txt'\n",
    "write_results(out_fpath, corpus_df, query_df, query_id_col, query_txt_col, X_tfidf, tfidf_vectorizer, run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell Output**\n",
    "\n",
    "```\n",
    "Wrote file @ ../data/output/tfidf_baseline_enhanced_abstract_query_question.txt\n",
    "\n",
    "CPU times: user 25min 55s, sys: 2.52 s, total: 25min 58s\n",
    "Wall time: 25min 58s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TF-IDF Settings\")\n",
    "pp.pprint(tfidf_vectorizer.get_params())\n",
    "print(\"\\nVocab.Size\")\n",
    "print(len(tfidf_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell Output**\n",
    "\n",
    "```\n",
    "TF-IDF Settings\n",
    "{   'analyzer': 'word',\n",
    "    'binary': False,\n",
    "    'decode_error': 'replace',\n",
    "    'dtype': <class 'numpy.float64'>,\n",
    "    'encoding': 'utf-8',\n",
    "    'input': 'content',\n",
    "    'lowercase': True,\n",
    "    'max_df': 0.9,\n",
    "    'max_features': None,\n",
    "    'min_df': 2,\n",
    "    'ngram_range': (1, 1),\n",
    "    'norm': 'l2',\n",
    "    'preprocessor': None,\n",
    "    'smooth_idf': True,\n",
    "    'stop_words': None,\n",
    "    'strip_accents': 'unicode',\n",
    "    'sublinear_tf': True,\n",
    "    'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "    'tokenizer': <bound method Tokenizer.tokenize of Tokenizer(config_codes=\"l-s-lm\")>,\n",
    "    'use_idf': True,\n",
    "    'vocabulary': None}\n",
    "\n",
    "Vocab.Size\n",
    "128777\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"enhanced_abstract_query_question\"\n",
    "path_to_qrel_file = \"../data/qrels/qrels-covid_d3_j0.5-3.txt\"\n",
    "path_to_result_file = f\"../data/output/tfidf_baseline_{run_name}.txt\"\n",
    "output_result_path = f\"../data/results/tfidf_baseline_{run_name}_trec_eval.txt\"\n",
    "os.system(\"trec_eval -c -m all_trec {} {} > {}\".format(path_to_qrel_file, path_to_result_file, output_result_path))\n",
    "with open(output_result_path, encoding='utf-8') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Metrics,\n",
    "\n",
    "- `MAP` - 0.1215\n",
    "- `NDCG@10` - 0.3127\n",
    "- `P@5` - 0.3750\n",
    "- `R@1000` - 0.3657\n",
    "\n",
    "Comparing "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
